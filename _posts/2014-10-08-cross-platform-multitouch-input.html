---
layout: post
title: Cross-Platform Multitouch Input
date: '2014-10-08T14:25:00.001+01:00'
author: Andre Weissflog
tags: 
modified_time: '2014-10-08T14:25:23.821+01:00'
blogger_id: tag:blogger.com,1999:blog-2948438400037317662.post-3075239553071729438
blogger_orig_url: http://flohofwoe.blogspot.com/2014/10/cross-platform-multitouch-input.html
---

<p><strong>TL;DR</strong>: A look at the low-level touch-input APIs on iOS, Android NDK and emscripten, and how to unify them for cross-platform engines with links to source code.</p> <h3 id="why">Why</h3> <p>Compared to mouse, keyboard and gamepad, handling multi-touch input is a complex topic because it usually involves gesture recognition, at least for simple gestures like tapping, panning and pinching. When I worked on mobile platforms in the past, I usually tried to avoid processing low-level touch input events directly, and instead used gesture recognizers provided by the platform SDKs:</p> <p>On <strong>iOS</strong> gesture recognizers are provided by the UIKit, they are attached to an UIView object, and when the gesture recognizer detects a gesture it will invoke a callback method. The details are here: <a href="https://developer.apple.com/library/ios/documentation/EventHandling/Conceptual/EventHandlingiPhoneOS/GestureRecognizer_basics/GestureRecognizer_basics.html">GestureRecognizer_basics.html</a></p> <p>The <strong>Android NDK</strong> itself has no built-in gesture recognizers, but comes with source code for a few simple gesture detectors in the <a href="https://android.googlesource.com/platform/development/+/master/ndk/sources/android/ndk_helper/">ndk_helpers source code directory</a></p> <p>There’s 2 problem with using SDK-provided gesture detectors. First, iOS and Android detectors behave differently. A pinch in the Android NDK is something slightly different then a pinch in the iOS SDK, and second, the <strong>emscripten SDK</strong> only provides the low-level touch events as provided by <a href="http://www.w3.org/TR/touch-events/">HTML5 Touch Event API</a>, no high-level gesture recognizers.</p> <p>So, to handle all 3 platforms in a common way, there doesn’t seem to be a way around writing your own gesture recognizers and trying to reduce the platform-specific touch event information into a platform-agnostic common subset.</p> <h3 id="platform-specific-touch-events">Platform-specific touch events</h3> <p>Let’s first look at the low-level touch events provided by each platform in order to merge their common attributes into a generic touch event:</p> <h4 id="ios-touch-events">iOS touch events</h4> <p>On iOS, touch events are forwarded to <strong>UIView</strong> callback methods (more specifically, <strong>UIResponder</strong>, which is a parent class of UIView). Multi-touch is disabled by default and must be enabled first by setting the property <strong>multipleTouchEnabled</strong> to YES.</p> <p>The callback methods are:</p>   <pre class="prettyprint"><code class=" hljs haml">-<span class="ruby"> <span class="hljs-symbol">touchesBegan:</span><span class="hljs-symbol">withEvent:</span><br /></span>-<span class="ruby"> <span class="hljs-symbol">touchesMoved:</span><span class="hljs-symbol">withEvent:</span><br /></span>-<span class="ruby"> <span class="hljs-symbol">touchesEnded:</span><span class="hljs-symbol">withEvent:</span><br /></span>-<span class="ruby"> <span class="hljs-symbol">touchesCancelled:</span><span class="hljs-symbol">withEvent:</span></span></code></pre> <p>All methods get an <strong>NSSet of UITouch</strong> object as first argument and an <strong>UIEvent</strong> as second argument.</p> <p>The arguments are a bit non-obvious: the set of UITouches in the first argument is not the overall number of current touches, but only the touches that have <em>changed their state</em>. So if there’s already 2 fingers down, and a 3rd finger touches the display, a <strong>touchesBegan</strong> will be received with a <strong>single UITouch object</strong> in the NSSet argument, which describes the touch of the 3rd finger that just came down. Same with <strong>touchEnded</strong> and <strong>touchMoved</strong>, if one of 3 fingers goes up (or moves), the NSSet will only contain a single UITouch object for the finger that has changed its state.</p> <p>The <em>overall</em> number of current touches is contained in the UIEvent object, so if 3 fingers are down, the UIEvent object contains 3 UITouch objects. The 4 callback methods and the NSSet argument are actually redundant, since all that information is also contained in the UIEvent object. A single <em>touchesChanged</em> callback method with a single UIEvent argument would have been enough to communicate the same information.</p> <p>Let’s have a <a href="https://developer.apple.com/library/ios/Documentation/UIKit/Reference/UIEvent_Class/index.html#//apple_ref/c/tdef/UIEventType">look at the information</a> provided by UIEvent, first there’s the method <strong>allTouches</strong> which returns an NSSet of all UITouch objects in the event and there’s a <strong>timestamp</strong> when the event occurred. The rest is contained in the returned <a href="https://developer.apple.com/library/ios/Documentation/UIKit/Reference/UITouch_Class/index.html#//apple_ref/occ/cl/UITouch">UITouch objects</a>:</p> <p>The UITouch method <strong>locationInView</strong> provides the position of the touch, the <strong>phase</strong> value gives the current state of the touch (began, moved, stationary, ended, cancelled). The rest is not really needed or specific to the iOS platform.</p> <h4 id="android-ndk-touch-events">Android NDK touch events</h4> <p>On Android, I assume that the Native Activity is used, with the <a href="https://android.googlesource.com/platform/development/+/master/ndk/sources/android/native_app_glue/android_native_app_glue.h">android_native_app_glue.h</a> helper classes. The application wrapper class <strong>android_app</strong> allows to set a single input event callback function which is called whenever an input event occurs. Android NDK input events and access functions are defined in the “android/input.h” header. The input event struct <strong>AInputEvent</strong> itself is isn’t public, and can only be accessed through accessor functions defined in the same header.</p> <p>When an input event arrives at the user-defined callback function, first check whether it is actually a touch event:</p> <pre class="prettyprint"><code class=" hljs fsharp">int32_t <span class="hljs-class"><span class="hljs-keyword">type</span> =</span> AInputEvent_getType(aEvent);<br /><span class="hljs-keyword">if</span> (AINPUT_EVENT_TYPE_MOTION == <span class="hljs-class"><span class="hljs-keyword">type</span>) {</span><br />  <span class="hljs-comment">// yep, a touch event</span><br />}</code></pre> <p>Once it’s sure that the event is a touch event, the <strong>AMotionEvent_</strong> set of accessor functions must be used to extract the rest of the information. There’s a whole lot of them, but we’re only interested in the attributes that are also provided by other platforms:</p>   <pre class="prettyprint"><code class=" hljs scss"><span class="hljs-function">AMotionEvent_getAction()</span>;<br /><span class="hljs-function">AMotionEvent_getEventTime()</span>;<br /><span class="hljs-function">AMotionEvent_getPointerCount()</span>;<br /><span class="hljs-function">AMotionEvent_getPointerId()</span>;<br /><span class="hljs-function">AMotionEvent_getX()</span>;<br /><span class="hljs-function">AMotionEvent_getY()</span>;</code></pre> <p>Together, these functions provide the same information as the iOS UIEvent object, but the information is harder to extract.</p> <p>Let’s start with the simple stuff: A motion event contains an array of touch points, called ‘pointers’, one for each finger touching the display. The number of touch points is returned by the <strong>AMotionEvent_getPointerCount()</strong> function, which takes an AInputEvent* as argument. The accessor functions <strong>AMotionEvent_getPointerId()</strong>, <strong>AMotionEvent_getX()</strong> and <strong>AMotionEvent_getY()</strong> take an AInputEvent* and an index to acquire an attribute of the touch point at the specified index. AMotionEvent_getX()/getY() extract the X/Y position of the touch point, and the AMotionEvent_getPointerId() function returns a unique id which is required to track the same touch point across several input events.</p> <p><strong>AMotionEvent_getAction()</strong> provides 2 pieces of information in a single return value: the actual ‘action’, and the index of the touch point this action applies to:</p> <p>The lower 8 bits of the return value contain the action code for a touch point that has changed state (whether a touch has started, moved, ended or was cancelled):</p> <pre class="prettyprint"><code class=" hljs ">AMOTION_EVENT_ACTION_DOWN<br />AMOTION_EVENT_ACTION_UP<br />AMOTION_EVENT_ACTION_MOVE<br />AMOTION_EVENT_ACTION_CANCEL<br />AMOTION_EVENT_ACTION_POINTER_DOWN<br />AMOTION_EVENT_ACTION_POINTER_UP</code></pre> <p>Note that there are 2 down events, DOWN and POINTER_DOWN. The NDK differentiates between ‘primary’ and ‘non-primary pointers’. The first finger down generates a DOWN event, the following fingers POINTER_DOWN events. I haven’t found a reason why these should be handled differently, so both DOWN and POINTER_DOWN events are handled the same in my code.</p> <p>The upper 24 bits contain the index (not the identifier!) of the touch point that has changed its state.</p> <h4 id="emscripten-sdk-touch-events">emscripten SDK touch events</h4> <p>Touch input in emscripten is provided by the new HTML5 wrapper API in the ‘emscripten/html5.h’ header which allows to set callback functions for nearly all types of HTML5 events (the complete API documentation <a href="http://kripken.github.io/emscripten-site/docs/api_reference/html5.h.html">can be found here</a>.</p> <p>To receive touch-events, the following 4 functions are relevant:</p> <pre class="prettyprint"><code class=" hljs bash">emscripten_<span class="hljs-keyword">set</span>_touchstart_callback()<br />emscripten_<span class="hljs-keyword">set</span>_touchend_callback()<br />emscripten_<span class="hljs-keyword">set</span>_touchmove_callback()<br />emscripten_<span class="hljs-keyword">set</span>_touchcancel_callback()</code></pre> <p>These set the application-provided callback functions that are called when a touch event occurs.</p> <p>There’s a caveat when handling touch input in the browser: usually a browser application doesn’t start in fullscreen mode, and the browser itself uses gestures for navigation (like scrolling, page-back and page-forward). The emscripten API allows to refine the events to specific DOM elements (for instance the WebGL canvas of the application instead of the whole HTML document), and the callback can decide to ‘swallow’ the event so that standard handling by the browser will be supressed.</p> <p>The first argument to the callback setter functions above is a C-string pointer identifying the DOM element. If this is a null pointer, events from the whole webpage will be received. The most useful value is “#canvas”, which limits the events to the (WebGL) canvas managed by the emscripten app.</p> <p>In order to suppress default  handling of an event, the event callback function should return ‘true’ (false if default handling should happen, but this is usually not desired, at least for games).</p> <p>The touch event callback function is called with the following arguments:</p> <pre class="prettyprint"><code class=" hljs cs"><span class="hljs-keyword">int</span> eventType,<br /><span class="hljs-keyword">const</span> EmscriptenTouchEvent* <span class="hljs-keyword">event</span><br /><span class="hljs-keyword">void</span>* userData</code></pre> <p><strong>eventType</strong> will be one of:</p>   <pre class="prettyprint"><code class=" hljs ">EMSCRIPTEN_EVENT_TOUCHSTART<br />EMSCRIPTEN_EVENT_TOUCHEND<br />EMSCRIPTEN_EVENT_TOUCHMOVE<br />EMSCRIPTEN_EVENT_TOUCHCANCEL</code></pre> <p>The 4 different callbacks are again kind of redundant (like in iOS), it often makes sense to route all 4 callbacks to the same handler function and differentiate there through the eventType argument.</p> <p>The actual touch event data is contained the EmscriptenTouchEvent structure, interesting for us is the member <strong>int numTouches</strong> and an array of <strong>EmscriptenTouchPoint</strong> structs. A single EmscriptenTouchPoint has the fields <strong>identifier</strong>, <strong>isChanged</strong> and the position of the touch in <strong>canvasX, canvasY</strong> (other member omitted for clarity).</p> <p>Except for the timestamp of the event, this is the same information provided by the iOS and Android NDK touch APIs.</p> <h4 id="bringing-it-all-together">Bringing it all together</h4> <p>The cross-section of all 3 touch APIs provides the following information:</p> <ul><li>a notification when the touch state changes: <br><ul><li>a touch-down was detected (a new finger touches the display)</li><li>a touch-up was detected (a finger was lifted off the display)</li><li>a movement was detected</li><li>a cancellation was detection</li></ul></li><li>information about all current touch points, and which of them has changed state <br><ul><li>the x,y position of the touch</li><li>a unique identifier in order to track the same touch point over several input events</li></ul></li></ul> <p>The touch point identifier is a bit non-obvious in the iOS API since the UITouch class doesn’t have an identifier member. On iOS, the pointer to an UITouch object serves as the identifier, the same UITouch object is guaranteed to exist as long as the touch is active.</p> <p>Also, another crucial piece of information is the timestamp when the event occurred. iOS and Android NDK provide this with their touch events, but not the emscripten SDK. Since the timestamps on Android and iOS have different meaning anyway, I’m simply tracking my own time when the events are received.</p> <p>My unified, platform-agnostic <strong>touchEvent</strong> now basically looks like this:</p> <pre class="prettyprint"><code class=" hljs rust"><span class="hljs-keyword">struct</span> touchEvent {<br />    <span class="hljs-keyword">enum</span> <span class="hljs-title">touchType</span> {<br />        began,<br />        moved,<br />        ended,<br />        cancelled,<br />        invalid,<br />    } <span class="hljs-keyword">type</span> = invalid;<br />    TimePoint time;<br />    int32 numTouches = <span class="hljs-number">0</span>;<br />    <span class="hljs-keyword">static</span> <span class="hljs-keyword">const</span> int32 MaxNumPoints = <span class="hljs-number">8</span>;<br />    <span class="hljs-keyword">struct</span> point {<br />        uintptr identifier = <span class="hljs-number">0</span>;<br />        glm::vec2 pos;<br />        <span class="hljs-keyword">bool</span> isChanged = <span class="hljs-keyword">false</span>;<br />    } points[MaxNumPoints];<br />}</code></pre> <p><strong>TimePoint</strong> is an Oryol-style timestamp object. The <strong>uintptr</strong> datatype for the identifier is an unsigned integer with the size of a pointer (32- or 64-bit depending on platform).</p> <p>Platform-specific touch events are received, converted to generic touch events, and then fed into custom gesture recognizers:</p> <ul><li><a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/ios/iosInputMgr.mm">iOS touch event source code</a></li><li><a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/android/androidInputMgr.cc">Android touch event source code</a></li><li><a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/emsc/emscInputMgr.cc">emscripten touch event source code (plus mouse and keyboard input handling)</a></li></ul> <p>Simple gesture detector source code: <br>- <a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/touch/tapDetector.cc">tap detector</a> <br>- <a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/touch/panDetector.cc">panning detector</a> <br>- <a href="https://github.com/floooh/oryol/blob/d640cf7840cabe866e34290e3a00c4309cc198a3/code/Modules/Input/touch/pinchDetector.cc">pinch detector</a></p> <p>And a simple demo (the WebGL version has only been tested on iOS8, mobile Safari’s WebGL implementation still has bugs): <br>- <a href="http://floooh.github.io/oryol/TestInput.html">WebGL demo</a> <br>- <a href="http://floooh.github.io/oryol/TestInput-debug.apk">Android self-signed APK</a></p> <p>And that’s all for today :)</p> <blockquote>  <p>Written with <a href="https://stackedit.io/">StackEdit</a>.</p></blockquote>